---
title: "Next-generation sequencing bulk segregant analysis with QTLseqr"
author: "Ben N. Mansfeld and Rebecca Grumet"
date: "`r Sys.Date()`"
output:
  rmarkdown::html_document:
    highlight: pygments
    toc: true
    fig_width: 5
abstract: > 
  Originally developed in the early 1990â€™s, Bulk Segregant Analysis (BSA) has since been an extremely useful tool for rapidly identifying markers in a genomic region associated with a trait of interest. QTL-seq is a relatively new and rapid way for performing bulk segregant analysis using next-generation sequencing data. However, no easy-to-use and multi-system compatible algorithms for performing this analysis are readily available.We developed the QTLseqr R package to allow for quick identification of genomic regions associated with traits of interest by combining two methods for bulk segregant analysis, $G'$ and $\Delta SNP\text{-}index$, described by Magwene et al. (2011) and Tagaki et al. (2013), respectively.Plotting of data is implemented in ggplot2 which allows for high-quality and customizable figures. QTLseqr package  version `r packageVersion("QTLseqr")` 
vignette: >
  %\VignetteIndexEntry{Next-generation sequencing bulk segregant analysis with QTLseqr}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, echo=FALSE, results="hide"}
knitr::opts_chunk$set(tidy=FALSE, cache=TRUE,
                      dev="png",
                      message=FALSE, error=FALSE, warning=TRUE)
```	

# Standard workflow

**If you use QTLseqr in published research, please cite:**

> Mansfeld B.N. and Grumet R,
> QTLseqr: An R package for bulk segregant analysis with next-generation sequencing
> *Journal* 2017, **other info**

## Quick Start
Here are the basic steps required to run and plot QTLseq and G' analysis

```{r quickStart, eval=FALSE}

#load the package
library("QTLseqr")

#Set sample and file names
HighBulk <- "SRR834931"
LowBulk <- "SRR834927"
file <- "SNPs_from_GATK.table"
#Choose which chromosomes will be included in the analysis (i.e. exclude smaller contigs)
Chroms <- paste0(rep("Chr", 12), 1:12)

#Import SNP data from file
df <-
    importFromGATK(
        filename = file,
        highBulk = HighBulk,
        lowBulk = LowBulk,
        chromList = Chroms
     )

#Filter SNPs based on some criteria
df_filt <-
    filterSNPs(
        df,
        refAlleleFreq = 0.20,
        minTotalDepth = 100,
        maxTotalDepth = 400,
        minSampleDepth = 40,
        minGQ = 99
    )


#Run G' analysis
df_filt <- runGprimeAnalysis(
    df_filt,
    windowSize = 1e6,
    outlierFilter = "deltaSNP")

#Plot
plotQTLStats(df_filt, var = "deltaSNP", plotThreshold = TRUE, q = 0.01)
plotQTLStats(df_filt, var = "Gprime", plotThreshold = TRUE, q = 0.01)
```

## Input data

QTLseqr currently only supports table format SNP data exported from the VariantsToTable function built in to GATK. We hope to support import from SAMtools/BCFtools as well as a simple table format, soon.

## Importing SNPs from GATK

Working directly with the [GATK best practices guide](https://software.broadinstitute.org/gatk/best-practices/bp_3step.php?case=GermShortWGS) for whole genome sequence should result in a VCF that is compatible with QTLseqr. In general the workflow suggested by GATK is per-sample variant calling followed by joint genotyping across samples. This will produce a VCF file that includes **BOTH** bulks, each with a different sample name (here SRR834927 and SRR834931), one SNP for example:

|CHROM|POS|ID|REF|ALT|QUAL|FILTER|INFO|FORMAT|SRR834927|SRR834931|
|-----|---|--|---|---|----|------|----|------|---------|---------|
|Chr1|31071|.|A|G|1390.44|PASS|..\*...|GT:AD:DP:GQ:PL|0/1:34,36:70:99:897,0,855|0/1:26,22:48:99:522,0,698|
Table :*\*info column removed for brevity*


GATK have provided a fast VCF parser, the [VariantsToTable](https://software.broadinstitute.org/gatk/documentation/tooldocs/current/org_broadinstitute_gatk_tools_walkers_variantutils_VariantsToTable.php) tool, that extracts the necessary fields for easy use in downstream analysis. 

We highly recommend reading [What is a VCF and how should I interpret it?](http://gatkforums.broadinstitute.org/gatk/discussion/1268/what-is-a-vcf-and-how-should-i-interpret-it) for more information on GATK VCF Fields and Genotype Fields

Though the use of GATK's VariantsToTable function is out of the scope of this vignette, the syntax for use with QTLseqr should look something like this:

```{bash, eval=FALSE}
java -jar GenomeAnalysisTK.jar \
-T VariantsToTable \
-R ${REF} \
-V ${NAME} \
-F CHROM -F POS -F REF -F ALT \
-GF AD -GF DP -GF GQ -GF PL \
-o ${NAME}.table
```
Where `${REF}` is the reference genome file and `${NAME}` is VCF file you wish to parse.

To run QTLseqr successfully, the required VCF fields `(-F)` are CHROM (Chromosome) and POS (Position). the required Genotype fields `(-GF)` are AD (Allele Depth), DP (Depth), GQ (Genotype Quality). Recommended fields are REF (Reference allele) and ALT (Alternative allele) Recommended Genotype fields are PL (Phred-scaled likelihoods)

### Import function

The `importFromGATK` function imports SNP data from the output of the VariantsToTable function in GATK. After importing the data, the function then calculates total reference allele frequency for both bulks together, the SNP index for each bulk, and the delta SNP index.

To demonstrate the use of this function we will load the Yang et al. (2013) data file.
```{r}
library("QTLseqr")
rawData <- system.file("extdata", "Yang_et_al_2013.table", package = "QTLseqr", mustWork = TRUE)
```
If you have your own data you can simply refer to it directly:
```{r, eval = FALSE}
rawData <- "C:/PATH/TO/MY/DIR/My_BSA_data.table"
```

We define the sample name for each of the bulks. This should corrispond to the sample names in the VCF returned by GATK. We also define a vector of the chromosomes to be included in the analysis (i.e. exclude smaller contigs), In this case, Chr1, Chr2 ... Chr12.
```{r}
HighBulk <- "SRR834931"
LowBulk <- "SRR834927"
Chroms <- paste0(rep("Chr", 12), 1:12)
```
We then use the `importFromGATK` function to import the raw data. After importing the data, the function then calculates total reference allele frequency for both bulks together, the $SNP\text{-}index$ for each SNP in each bulk and the $\Delta SNP\text{-}index$ and returns a data frame.

$$Reference\ allele\ frequency = \frac{Ref\ allele\ depth_{HighBulk} + Ref\ allele\ depth_{LowBulk}}{Total\ read\ depth\ for\ both\ bulks}$$

$$SNP\text{-}index_{per\ bulk} = \frac{Alternate\ allele\ depth}{Total\ read\ depth}$$
$$\Delta SNP\text{-}index = SNP \text{-} index_{High Bulk} - SNP\text{-}index_{Low Bulk}$$

Let's import 
```{r import, cache=TRUE}
#import data
df <-
    importFromGATK(
        filename = rawData,
        highBulk = HighBulk,
        lowBulk = LowBulk,
        chromList = Chroms
     )
```

### Loaded data frame
The loaded data frame should look like this:
```{r viewdf}
head(df)
```

Let's review the column headers:

* CHROM - The chromosome this SNP is in
* POS - The position on the chromosome in nt
* REF - The reference allele at that position
* ALT - The alternate allele
* DP.HIGH - The read depth at that position in the high bulk
* AD_REF.HIGH - The allele depth of the reference allele in the high bulk
* AD_ALT.HIGH - The alternate allele depth in the the high bulk
* GQ.HIGH - The genotype quality score, (how confident we are in the genotyping)
* SNPindex.HIGH - The calculated SNP-index for the high bulk
* Same as above for the low bulk
* REF_FRQ - The reference allele frequency as defined above
* deltaSNP - The $\Delta SNP\text{-}index$ as defined above

## Filtering SNPs
Now that we have loaded the data into R we can start cleaning it up by filtering some of the low confidence SNPs.
While GATK has its own filtering tools, QTLseqr offers some options for filtering that may help reduce noise and improve results. Filtering is mainly based on read depth for each SNP, such that we can try to elliminate SNPs with low confidence, due to low coverage, and SNPs that may be in repetitive regions and thus have inflated read depth. 

### Read depth histograms

One way to assess filtering thresholds is by plotting histograms of the read depths. We can get an idea of where to draw our thresholds. We'll use the ggplot2 package for this purpose, but you could use base R to plot as well.

Lets look at total read depth for example:
```{r plothist1, warning = FALSE, fig.align="center", fig.width=4, fig.height=4}
library("ggplot2")
ggplot(data = df) + 
    geom_histogram(aes(x = DP.HIGH + DP.LOW)) + 
    xlim(0,1000)

```

...or look at total reference allele frequency:
```{r plothist2, warning=FALSE, fig.align="center", fig.width=4, fig.height=4}
ggplot(data = df) +
    geom_histogram(aes(x = REF_FRQ))
```

### Using the filterSNPs function
Now that we have an idea about our read depth distribution we can filter out low confidence SNPS. In general we recommend filtering extremely low and high coverage SNPs, either in both bulks (`minTotalDepth/maxTotalDepth`) or in each bulk separately (`minSampleDepth`). We have the option to filter based on reference allele frequency (`refAlleleFreq`), this removes SNPs that for some reason are over- or under-represented in *BOTH* bulks. We can also use the GATK GQ score (Genotype Quality) to filter out low confidence SNPs. If the `verbose` paramater is set to `TRUE` (default) the function will report the numbers of SNPs filtered in each step.
```{r filtSNPs-source, eval = FALSE, message = FALSE}
df_filt <-
    filterSNPs(
        SNPset = df,
        refAlleleFreq = 0.20,
        minTotalDepth = 100,
        maxTotalDepth = 400,
        minSampleDepth = 40,
        minGQ = 99,
        verbose = TRUE
    )
```

```{r filtSNPs-msgs, message = TRUE, warning = FALSE, collapse = TRUE, echo = FALSE}
df_filt <-
    filterSNPs(
        SNPset = df,
        refAlleleFreq = 0.20,
        minTotalDepth = 100,
        maxTotalDepth = 400,
        minSampleDepth = 40,
        minGQ = 99,
        verbose = TRUE
    )
```

This step is quick and we can go back and plot some histograms to see if we are happy with the results, and we can quickly re-run the filtering step if not.

## Running the analysis

The analysis in QTLseqr is an implementation of both pipelines for bulk segregant analysis, $G'$ and $\Delta SNP\text{-}index$, described by Magwene et al. (2011) and Tagaki et al. (2013), respectively. We recommend reading both papers to fully understand the conciderations and math behind the analysis. 
Here, we will breifly summarize the steps performed by the main analysis function, `runGprimeAnalysis`.

The following steps are performed:

1. First the number of SNPs within the sliding window are counted.

1. A tricube-smoothed $\Delta SNP\text{-}index$ is calculated within the set window size.

1. Genome-wide G statistics are calculated by `getG`.
$G$ is defined by the equation:

$$G = 2 * âˆ‘ n_i * ln(\frac{obs(n_i)}{exp(n_i)})$$

Where for each SNP, $n_i$ from i = 1 to 4 corresponds to the reference and alternate allele depths for each bulk, as described in the following table:

|Allele|High Bulk|Low Bulk|
|------|---------|--------|
|Reference| $n_1$	| $n_2$ |
|Alternate| $n_3$	| $n_4$ |

...and $obs(n_i)$ are the observed allele depths as described in the data frame. `getG` calculates the G statistic using expected values assuming read depth is equal for all alleles in both bulks:
$$
exp(n_1) = \frac{(n_1 + n_2)*(n_1 + n_3)}{(n_1 + n_2 + n_3 + n_4)}
$$ 
$$
exp(n_2) = \frac{(n_2 + n_1)*(n_2 + n_4)}{(n_1 + n_2 + n_3 + n_4)}
$$
$$
exp(n_3) = \frac{(n_3 + n_1)*(n_3 + n_4)}{(n_1 + n_2 + n_3 + n_4)}
$$
$$
exp(n_4) = \frac{(n_4 + n_2)*(n_4 + n_3)}{(n_1 + n_2 + n_3 + n_4)}
$$

1. G' - A tricube-smoothed G statistic is predicted by constant local regression within each chromosome using the `tricubeStat` function. This works as a weighted average across neighboring SNPs that accounts for Linkage disequilibrium (LD) while minizing noise attributed to SNP calling errors. G values for neighboring SNPs within the window are weighted by physical distance from the focal SNP. 

1. P-values are estimated based using the non-parametric method described by Magwene et al. 2011 with the function `getPvals`. Breifly, using the natural log of $G'$ a median absolute deviation (MAD) is calculated. The $G'$ set is trimmed to exclude outlier regions (i.e. QTL) based on Hampel's rule. An alternate method for filtering out QTL that we propose is using absolute $\Delta SNP\text{-}index$ values greater than 0.1 to filter out potential QTL. An estimation of the mode of the trimmed set is calculated using the `mlv` function from the package modeest. Finally, the mean and variance of the set are estimated using the median and mode and p-values are estimated from a log normal distribution. 

1. Negative Log10- and Benjamini-Hochberg adjusted p-values are calculated using `p.adjust`.

Let's run the function:

```{r gprimeanalysis-src, eval = FALSE}
df_filt <- runGprimeAnalysis(df_filt,
    windowSize = 1e6,
    outlierFilter = "deltaSNP")
```
```{r gprimeanalysis-msg, message = TRUE, warning = FALSE, collapse = TRUE, echo = FALSE}
df_filt <- runGprimeAnalysis(df_filt,
    windowSize = 1e6,
    outlierFilter = "deltaSNP")
```
As this is window is using a tricube-smoothing kernel the window size *can* be much larger than you might expect. We however choose a window size of 1Mb for the sliding window analysis, for a discussion about window size we recommend reading Magwene et al. (2011). In general larger windows will produced smoother data. The functions making these calculations are rather fast, so we recommend testing several window sizes for your data, and deciding on the optimal size.

Some additional columns are added to the filtered data frame:
```{r}
head(df_filt)
```

* nSNPs - the number of SNPs braketing the focal SNP within the set sliding window
* tricubeDeltaSNP - the tricube-smoothed $\Delta SNP\text{-}index$
* G - the G value for the SNP
* Gprime - the tricube-smoothed G value
* pvalue - the p-value calculated by non-parametric estimation
* negLog10Pval - the $-log_{10}(p\text{-}value)$ 
* qvalue - Benjamini-Hochberg adjusted p-values

## Plotting the data

QTLseqr offers two main plotting functions to check the validity of the G' analysis and to plot genome-wide or chromosome specific QTL analysis plots.

### G' distribution plots

Due to the fact that p-values are estimated from the null distribution of G', an important check is to see if G' values are close to log normally distributed. For this purpose we use the `plotGprimeDist` function, which plots the G' density estimates alongside the lognormal null distribution. We can also use this to test which filtering method (Hampel or DeltaSNP) estimates a more accurate null distribution.

```{r gprimedist hampel, message = FALSE, warning = FALSE, fig.align = "center", fig.height=4 }
plotGprimeDist(SNPset = df_filt, outlierFilter = "Hampel")

```

```{r gprimedist deltaSNP, message=FALSE, warning = FALSE, fig.align = "center", fig.height=4}
plotGprimeDist(SNPset =df_filt, outlierFilter = "deltaSNP")
```

### QTL analysis plots
Now that we are happy with our filtered data and it seems that the G' distribution is close to lognormal, we can finally plot some genome-wide figures and try to identify QTL.

Let's start by plotting the SNP/window distribution:
```{r plotnSNPs, fig.align="center", fig.width=12, fig.height=4}
p1 <- plotQTLStats(SNPset = df_filt, var = "nSNPs")
p1
```
This is informative as we can assess if there are regions with extremely low SNP density.

More importantly lets identify some QTL by plotting the smoothed $\Delta SNP\text{-}index$ and $G'$ values.

```{r plotdeltaSNP, fig.align="center", fig.width=12, fig.height=4}
p2 <- plotQTLStats(SNPset = df_filt, var = "deltaSNP")
p2
```
We can see that there are some regions that have $|\Delta SNP\text{-}index| > 0.3$ these may be QTL. The directionality of the $\Delta SNP\text{-}index$ is also important. If the allele contributing to the trait is from the reference parent the $\Delta SNP\text{-}index$ should be less than 0. However, if the $\Delta SNP\text{-}index > 0$ then the contributing parent is the one with the alternate alleles. 

Let's look at the $G'$ values to see if these regions are significant and pass the FDR (q) of 0.01.
```{r plotGprime, fig.align="center", fig.width=12, fig.height=4}
p3 <- plotQTLStats(SNPset = df_filt, var = "Gprime", plotThreshold = TRUE, q = 0.01)
p3
```

Great! It looks like there are QTL identified on Chromosomes 1, 2, 5, 8 and 10.
Based on the $\Delta SNP\text{-}index$ and $G'$ plots the QTL from Chr1 originates from the reference parent (Nipponbare rice, in this case) and the QTL on Chr8 was contributed by the other parent, for example.

We can also use the `plotQTLStats` function to the $-log_{10}(p\text{-}value)$. While this number is a direct dirivitive of $G'$ it can be more self explanitory for some. We can use the subset paramater to plot one or a few of the chomosomes, say for a close up figure of a QTL of interest.

```{r subsetlogpval, fig.align="center", fig.width=6, fig.height=4}
QTLplots <- plotQTLStats(SNPset = df_filt, var = "negLog10Pval", plotThreshold = TRUE, q = 0.01, subset = c("Chr1", "Chr8"))
QTLplots
```

## Extracting QTL data

Now that we've plotted and identified some putative QTL we can extract the data using two functions `getSigRegions` and `getQTLTable`.

The `getSigRegions` function will produce a list in which each element represents a QTL region. The elements are subseted from the orignal data frame you supplied. Any contiguous region above with an adjusted p-value above the set alpha will be returned. If there is a dip below the alpha this region will be split to two elements. 

Let's examine the `head` of the first QTL:
```{r getsigreg}
QTL <- getSigRegions(SNPset = df_filt, alpha = 0.01)
head(QTL[[1]])
```