---
title: "Next-generation sequencing bulk segregant analysis with QTLseqr"
author: "Ben N. Mansfeld and Rebecca Grumet"
date: "`r Sys.Date()`"
output:
  rmarkdown::html_document:
    highlight: pygments
    toc: true
    fig_width: 5
abstract: > 
  Originally developed in the early 1990â€™s, Bulk Segregant Analysis (BSA) has since been an extremely useful tool for rapidly identifying markers in a genomic region associated with a trait of interest. QTL-seq is a relatively new and rapid way for performing bulk segregant analysis using next-generation sequencing data. However, no easy-to-use and multi-system compatible algorithms for performing this analysis are readily available.We developed the QTLseqr R package to allow for quick identification of genomic regions associated with traits of interest by combining two methods for bulk segregant analysis, $G'$ and $\Delta SNP\text{-}index$, described by Magwene et al. (2011) and Tagaki et al. (2013), respectively.Plotting of data is implemented in ggplot2 which allows for high-quality and customizable figures. QTLseqr package  version `r packageVersion("QTLseqr")` 
vignette: >
  %\VignetteIndexEntry{Next-generation sequencing bulk segregant analysis with QTLseqr}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, echo=FALSE, results="hide"}
knitr::opts_chunk$set(tidy=FALSE, cache=TRUE,
                      dev="png",
                      message=FALSE, error=FALSE, warning=TRUE)
```	

# Standard workflow

**If you use QTLseqr in published research, please cite:**

> Mansfeld B.N. and Grumet R,
> QTLseqr: An R package for bulk segregant analysis with next-generation sequencing
> *Journal* 2017, **other info**

## Quick Start
Here are the basic steps required to run and plot QTLseq and G' analysis

```{r quickStart, eval=FALSE}

#load the package
library("QTLseqr")

#Set sample and file names
HighBulk <- "SRR834931"
LowBulk <- "SRR834927"
file <- "SNPs_from_GATK.table"
#Choose which chromosomes will be included in the analysis (i.e. exclude smaller contigs)
Chroms <- paste0(rep("Chr", 12), 1:12)

#Import SNP data from file
df <-
    importFromGATK(
        filename = file,
        highBulk = HighBulk,
        lowBulk = LowBulk,
        chromList = Chroms
     )

#Filter SNPs based on some criteria
df_filt <-
    filterSNPs(
        df,
        refAlleleFreq = 0.20,
        minTotalDepth = 100,
        maxTotalDepth = 400,
        minSampleDepth = 40,
        minGQ = 99
    )


#Run G' analysis
df_filt <- runGprimeAnalysis(
    df_filt,
    windowSize = 1e6,
    outlierFilter = "deltaSNP")

#Plot
plotQTLStats(df_filt, var = "deltaSNP", plotThreshold = TRUE, q = 0.01)
plotQTLStats(df_filt, var = "Gprime", plotThreshold = TRUE, q = 0.01)
```

## Input data

QTLseqr currently only supports table format SNP data exported from the VariantsToTable function built in to GATK. We hope to support import from SAMtools/BCFtools as well as a simple table format, soon.

## Importing SNPs from GATK

Working directly with the [GATK best practices guide](https://software.broadinstitute.org/gatk/best-practices/bp_3step.php?case=GermShortWGS) for whole genome sequence should result in a VCF that is compatible with QTLseqr. In general the workflow suggested by GATK is per-sample variant calling followed by joint genotyping across samples. This will produce a VCF file that includes **BOTH** bulks, each with a different sample name (here SRR834927 and SRR834931), one SNP for example:

|CHROM|POS|ID|REF|ALT|QUAL|FILTER|INFO|FORMAT|SRR834927|SRR834931|
|-----|---|--|---|---|----|------|----|------|---------|---------|
|Chr1|31071|.|A|G|1390.44|PASS|..\*...|GT:AD:DP:GQ:PL|0/1:34,36:70:99:897,0,855|0/1:26,22:48:99:522,0,698|
*\*info column removed for brevity*


GATK have provided a fast VCF parser, the [VariantsToTable](https://software.broadinstitute.org/gatk/documentation/tooldocs/current/org_broadinstitute_gatk_tools_walkers_variantutils_VariantsToTable.php) tool, that extracts the necessary fields for easy use in downstream analysis. 

We highly recommend reading [What is a VCF and how should I interpret it?](http://gatkforums.broadinstitute.org/gatk/discussion/1268/what-is-a-vcf-and-how-should-i-interpret-it) for more information on GATK VCF Fields and Genotype Fields

Though the use of GATK's VariantsToTable function is out of the scope of this vignette, the syntax for use with QTLseqr should look something like this:

```{bash, eval=FALSE}
java -jar GenomeAnalysisTK.jar \
-T VariantsToTable \
-R ${REF} \
-V ${NAME} \
-F CHROM -F POS -F REF -F ALT \
-GF AD -GF DP -GF GQ -GF PL \
-o ${NAME}.table
```
Where `${REF}` is the reference genome file and `${NAME}` is VCF file you wish to parse.

To run QTLseqr successfully, the required VCF fields `(-F)` are CHROM (Chromosome) and POS (Position). the required Genotype fields `(-GF)` are AD (Allele Depth), DP (Depth), GQ (Genotype Quality). Recommended fields are REF (Reference allele) and ALT (Alternative allele) Recommended Genotype fields are PL (Phred-scaled likelihoods)

### Import function

The `importFromGATK` function imports SNP data from the output of the VariantsToTable function in GATK. After importing the data, the function then calculates total reference allele frequency for both bulks together, the SNP index for each bulk, and the delta SNP index.

To demonstrate the use of this function we will load the Yang et al. (2013) data file.
```{r}
library("QTLseqr")
rawData <- system.file("extdata", "Yang_et_al_2013.table", package = "QTLseqr", mustWork = TRUE)
```
If you have your own data you can simply refer to it directly:
```{r, eval = FALSE}
rawData <- "C:/PATH/TO/MY/DIR/My_BSA_data.table"
```

We define the sample name for each of the bulks. This should corrispond to the sample names in the VCF returned by GATK. We also define a vector of the chromosomes to be included in the analysis (i.e. exclude smaller contigs), In this case, Chr1, Chr2 ... Chr12.
```{r}
HighBulk <- "SRR834931"
LowBulk <- "SRR834927"
Chroms <- paste0(rep("Chr", 12), 1:12)
```
We then use the `importFromGATK` function to import the raw data. After importing the data, the function then calculates total reference allele frequency for both bulks together, the $SNP\text{-}index$ for each SNP in each bulk and the $\Delta SNP\text{-}index$ and returns a data frame.

$$Reference\ allele\ frequency = \frac{Ref\ allele\ depth_{HighBulk} + Ref\ allele\ depth_{LowBulk}}{Total\ read\ depth\ for\ both\ bulks}$$

$$SNP\text{-}index_{per\ bulk} = \frac{Alternate\ allele\ depth}{Total\ read\ depth}$$
$$\Delta SNP\text{-}index = SNP \text{-} index_{High Bulk} - SNP\text{-}index_{Low Bulk}$$

Let's import 
```{r, cache = TRUE}
#import data
df <-
    importFromGATK(
        filename = rawData,
        highBulk = HighBulk,
        lowBulk = LowBulk,
        chromList = Chroms
     )
```

### Loaded data frame
The loaded data frame should look like this:
```{r}
head(df)
```

Let's review the column headers:

* CHROM - The chromosome this SNP is in
* POS - The position on the chromosome in nt
* REF - The reference allele at that position
* ALT - The alternate allele
* DP.HIGH - The read depth at that position in the high bulk
* AD_REF.HIGH - The allele depth of the reference allele in the high bulk
* AD_ALT.HIGH - The alternate allele depth in the the high bulk
* GQ.HIGH - The genotype quality score, (how confident we are in the genotyping)
* SNPindex.HIGH - The calculated SNP-index for the high bulk
* Same as above for the low bulk
* REF_FRQ - The reference allele frequency as defined above
* deltaSNP - The $\Delta SNP\text{-}index$ as defined above

## Filtering SNPs
Now that we have loaded the data into R we can start cleaning it up by filtering some of the low confidence SNPs.
While GATK has its own filtering tools, QTLseqr offers some options for filtering that may help reduce noise and improve results. Filtering is mainly based on read depth for each SNP, such that we can try to elliminate SNPs with low confidence, due to low coverage, and SNPs that may be in repetitive regions and thus have inflated read depth. 

### Read depth histograms

One way to assess filtering thresholds is by plotting histograms of the read depths. We can get an idea of where to draw our thresholds. We'll use the ggplot2 package for this purpose, but you could use base R to plot as well.

Lets look at total read depth for example:
```{r, warning = FALSE}
library("ggplot2")
ggplot(data = df) + 
    geom_histogram(aes(x = DP.HIGH + DP.LOW)) + 
    xlim(0,1000)

```

...or look at total reference allele frequency:
```{r, warning=FALSE}
ggplot(data = df) +
    geom_histogram(aes(x = REF_FRQ))
```

### Using the filterSNPs function
Now that we have an idea about our read depth distribution we can filter out low confidence SNPS. In general we recommend filtering extremely low and high coverage SNPs, either in both bulks (`minTotalDepth/maxTotalDepth`) or in each bulk separately (`minSampleDepth`). We have the option to filter based on reference allele frequency (`refAlleleFreq`), this removes SNPs that for some reason are over- or under-represented in *BOTH* bulks. We can also use the GATK GQ score (Genotype Quality) to filter out low confidence SNPs. If the `verbose` paramater is set to `TRUE` (default) the function will report the numbers of SNPs filtered in each step.
```{r filtSNPs-source, eval = FALSE, message = FALSE}
df_filt <-
    filterSNPs(
        SNPset = df,
        refAlleleFreq = 0.20,
        minTotalDepth = 100,
        maxTotalDepth = 400,
        minSampleDepth = 40,
        minGQ = 99,
        verbose = TRUE
    )
```

```{r filtSNPs-msgs, message = TRUE, warning = FALSE, collapse = TRUE, echo = FALSE}
df_filt <-
    filterSNPs(
        SNPset = df,
        refAlleleFreq = 0.20,
        minTotalDepth = 100,
        maxTotalDepth = 400,
        minSampleDepth = 40,
        minGQ = 99,
        verbose = TRUE
    )
```

This step is quick and we can go back and plot some histograms to see if we are happy with the results, and we can quickly re-run the filtering step if not.

## Running the analysis

The `html_vignette` template includes a basic CSS theme. To override this theme you can specify your own CSS in the document metadata as follows:

    output: 
      rmarkdown::html_vignette:
        css: mystyles.css

## Figures

The figure sizes have been customised so that you can easily put two images side-by-side. 

```{r, fig.show='hold'}
plot(1:10)
plot(10:1)
```

You can enable figure captions by `fig_caption: yes` in YAML:

    output:
      rmarkdown::html_vignette:
        fig_caption: yes

Then you can use the chunk option `fig.cap = "Your figure caption."` in **knitr**.

## More Examples

You can write math expressions, e.g. $Y = X\beta + \epsilon$, footnotes^[A footnote here.], and tables, e.g. using `knitr::kable()`.

```{r, echo=FALSE, results='asis'}
knitr::kable(head(mtcars, 10))
```

Also a quote using `>`:

> "He who gives up [code] safety for [code] speed deserves neither."
([via](https://twitter.com/hadleywickham/status/504368538874703872))
